## Methods

Methods go here.

### Experimental

#### Primate brain organoid protocols

We did things.
One sentence per line.
Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].

#### Single-cell capture of primate brain organoids

We did things.
One sentence per line.
Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].

#### Long read library prep

We did things.
One sentence per line.
Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].


#### Short read library prep

We did things.
One sentence per line.
Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].

#### Sequencing

We did things.
One sentence per line.
Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].

### Computational

![Caption for Supplemental figure 1](images/supplemental_figure1.svg){#sfig:sfig1 tag="sfig1" width="100%"}

#### $k$-mer comparison of orthologous genes

We used ENSEMBL version 97.
We did things.
One sentence per line.
Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].

#### Extraction of putative coding reads from RNA-seq

We did things.
One sentence per line.
Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].

#### $bam2fasta$ conversion

The `.bam` file generated by the Drop-seq [@doi:10.1016/j.cell.2015.05.002] pipeline for the different primates in this study are in the order of 6-12 GB.
The Drop-seq `.bam` files so obtained can attribute to few limitations as discussed below.
Firstly, loading them in memory all at once would require a lot of RAM depending on how the program will allocate memory for different data typed tags in the `.bam` file.
Secondly, if Drop-seq data is not accompanied by a barcodes file to filter the `.bam` file on, it would mean we would have to recursively go through the alignments in the bam file and deduce alignments with higher quality and combine sequences with already exisiting barcodes.
This would need a look up dictionary to be updated as it loops through the alignments in the `.bam` file and would search the look up dictionary as it updates the barcodes.
In conclusion, this is a very memory intensive process that seemed to fail on even machines with 2TB RAM.


Hence we propose a method that could work on a computer with lesser RAM and not cause computer hangups.
We released an open source pypi package for the same [@url:https://pypi.org/project/bam2fasta/].
The package contains solution for the above discussed problem by sharding the `.bam` file into chunks of smaller `.bam` files and stores them in the machine's temporary folder, e.g. `/tmp`.
The chunk size of the `.bam` file is a tunable parameter that can be accessed with `--line_count`; by default it is 1500 alignment lines.
This process is done serially by iterating through the alignments in the `.bam` file, using `pysam`, a Python wrapper around samtools [@doi:10.1093/bioinformatics/btp352].
Now we employ a MapReduce [@doi:10.1145/1327452.1327492] approach to the temporary `.bam` files to obtain all the reads per cell barcode in a `.fasta` file.
In the "Map" step, we distribute the computation i.e parsing the barcode, determining the quality of the read, and if alignment is not duplicated, in parallel across multiple processes on the temporary shards of `.bam` files.
These bam shards create temporary `.fasta` files that contain for each read: the cell barcode, unique molecular identifier (UMI), and the aligned sequence.
There might be a cell barcode that would be present in different chunks of these sharded `.bam` files.
As a result we would have multiple temporary `.fasta` files for the same barcodes.
We implemented a method to find the unique barcodes based on these temporary `.fasta` file names and then assigning each of the unique barcodes all the temporary barcode `.fasta` files created by different `.bam` shards in a dictionary.
In the "Reduce" step, we concatenate of strings of temporary `.fasta` file names, hence its memory consumption is less than it would be if appending to a list.
These temporary `.fasta` files are then combined to one `.fasta` file per barcode by concatenating all the sequences obtained from different `.fasta` files.
The concatenation of all sequences for each of the unique barcodes is also then parallelized to use multiple processes.
For each of the cell barcodes, there is an option to obtain valid cell barcodes, based on the UMI count per cell barcode.
For our datasets we have set the minimum number of UMIs per cell barcode to 1000, a common threshold.
The minimum number of UMIs per cell barcode can be customized with the flag `--min-umi-per-barcode`.
The computational resources and time taken for processing is as shown in Table [@tbl:bam2fasta-runtime-ram].


|  Primate  | BAM file size(GB)  | Time(hrs)| RAM(GB) | Processes |
| :-------- | :------------------| :--------| :-------| :---------|
| Human     | 12                 | 7        | 16      | 32        |
| Orangutan | 9                  | 4        | 16      | 32        |
| Chimp     | 9                  | 4        | 16      | 32        |

Table: Human primate species bam file here is from a brain organoid for human {#tbl:bam2fasta-runtime-ram}

This method primarily gives us time performance improvement.
It reduces time from days or just process running out of memory to hours.
Depending on the size of `.bam` file and resources of the cluster/computer it can be further reduced.

Prefer DOI for references, but for Biorxiv use the URL.
DOI example: [@doi:10.1038/nmeth.3830].
Biorxiv example: [@url:https://doi.org/10.1101/466201].
Multiple citations per line example: [@doi:10.1038/nmeth.3830; @url:https://doi.org/10.1101/466201].


## Supplemental Methods




|  Amino acid                    | Property              | Dayhoff | Hydrophobic-polar (HP) |
| :----------------------------- | :-------------------- | :------ | :--------------------- |
| C                              | Sulfur polymerization | a       | p                      |
| A, G, P, S, T                  | Small                 | b       | A, G, P: h             |
|                                |                       |         | S,T: p                 |
| D, E, N, Q                     | Acid and amide        | c       | p                      |
| H, K, R                        | Basic                 | d       | p                      |
| I, L, M, V                     | Hydrophobic           | e       | h                      |
| F, W, Y                        | Aromatic              | f       | h                      |

Table: Dayhoff and hydrophobic-polar encodings are a reduced amino acid
alphabet allowing for permissive cross-species sequence comparisons. For
example, the amino acid sequence `SASHAFIERCE` would be Dayhoff-encoded
to `bbbdbfecdac`, and HP-encoded to `phpphhhpppp`. {#tbl:sequence-encodings}
